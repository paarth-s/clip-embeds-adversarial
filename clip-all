{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzOkJopIxzhH",
        "outputId": "6f3cbbad-596c-4124-8520-bb926d833854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-sweaf_mg\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 1: conda: command not found\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-sweaf_mg\n"
          ]
        }
      ],
      "source": [
        "#these cells install CLIP and other libraries\n",
        "#and process data from images to embeddings to np formats\n",
        "#and train an mlp classifier on the transformed data\n",
        "%%bash\n",
        "conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
        "pip install ftfy regex tqdm\n",
        "pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2Jf_wB0xfmL"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import h5py\n",
        "import clip\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyOvsb3DyCOP"
      },
      "outputs": [],
      "source": [
        "#more env and clip setup\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more env setup\n",
        "if ('google' in str(get_ipython())):\n",
        "    from google.colab import drive\n",
        "    drive.mount('ME')\n",
        "    predir='ME/My Drive/'\n",
        "else:\n",
        "    predir = os.path.join('Users','amit','Google Drive')\n",
        "    if os.path.isdir(os.path.join(predir,'My Drive')):\n",
        "            predir=os.path.join(predir,'My Drive')\n",
        "\n",
        "datadir=predir+'LSDA_data/'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggGORjYmBw4l",
        "outputId": "6e8a0bd7-2532-42dd-a887-dd9494ada46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ME; to attempt to forcibly remount, call drive.mount(\"ME\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGdexgd-uRlX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#gets MNIST data, took this func from one of yali's hws\n",
        "def get_mnist():\n",
        "    data=np.float64(np.load(datadir+'mnist/MNIST_data.npy'))\n",
        "    labels=np.float32(np.load(datadir+'mnist/MNIST_labels.npy'))\n",
        "    #print(data.shape)\n",
        "    data=np.float32(data)/255.\n",
        "    data_tr_all=data[0:70000].reshape((-1,28,28))\n",
        "    labels_tr_all=np.int32(labels[0:70000])\n",
        "    \"\"\"\n",
        "    train_dat=data[0:50000].reshape((-1,28,28))\n",
        "    train_labels=np.int32(labels[0:50000])\n",
        "\n",
        "    train2_dat=data[50000:55000].reshape((-1,28,28))\n",
        "    train2_labels=np.int32(labels[50000:55000])\n",
        "\n",
        "    train3_dat=data[55000:60000].reshape((-1,28,28))\n",
        "    train3_labels=np.int32(labels[55000:60000])\n",
        "\n",
        "    test_dat=data[60000:70000].reshape((-1,28,28))\n",
        "    test_labels=np.int32(labels[60000:70000])\"\"\"\n",
        "    \n",
        "    return (data_tr_all, labels_tr_all)#,(train_dat, train_labels), (train2_dat, train2_labels), (train3_dat, train3_labels), (test_dat, test_labels)\n",
        "\n",
        "#custom trainging set split for testing\n",
        "def trainSplit(blur_pct, shift_pct):\n",
        "    labels = data_now[1]\n",
        "    blur_pct_true = blur_pct/100.0\n",
        "    shift_pct_true = shift_pct/100.0\n",
        "    #print(blur_pct_true)\n",
        "    #print(shift_pct_true)\n",
        "\n",
        "    blur_num = np.int32(blur_pct_true * 60000)\n",
        "    shift_num = blur_num + np.int32(shift_pct_true * 60000)\n",
        "    #print(blur_num)\n",
        "    #print(shift_num)\n",
        "\n",
        "    blurDat = this_split_blur_embeds_w_labels[0]\n",
        "    train_blur_split = blurDat[0:blur_num]\n",
        "    train_blur_labels = np.int32(labels[0:blur_num])\n",
        "    #add blur function from matt\n",
        "\n",
        "    shiftDat = this_split_shift_embeds_w_labels[0]\n",
        "    train_shift_split = shiftDat[blur_num:shift_num]\n",
        "    train_shift_labels = np.int32(labels[blur_num:shift_num])\n",
        "    #add shift function from matt\n",
        "\n",
        "    rawDat = this_split_raw_embeds_w_labels[0]\n",
        "    #print(rawDat.shape)\n",
        "    #print(shift_num)\n",
        "    train_raw_split = rawDat[shift_num:60000]\n",
        "    train_raw_labels = np.int32(labels[shift_num:60000])\n",
        "\n",
        "    return (train_raw_split, train_raw_labels), (train_blur_split, train_blur_labels), (train_shift_split, train_shift_labels)\n",
        "\n",
        "\n",
        "def get_cifar():\n",
        "    with h5py.File(datadir+'CIFAR/cifar10_train.hdf5', \"r\") as f:\n",
        "        tr=f[('data')][:].transpose(0,3,1,2)\n",
        "        tr_lb=f[('labels')][:]\n",
        "    train_data=np.float32(tr[0:45000])/255.\n",
        "    train_labels=tr_lb[0:45000]\n",
        "    val_data=np.float32(tr[45000:])/255.\n",
        "    val_labels=tr_lb[45000:]\n",
        "\n",
        "    with h5py.File(datadir+'CIFAR/cifar10_test.hdf5', \"r\") as f:\n",
        "        test_data=f[('data')][:].transpose(0,3,1,2)\n",
        "        test_data=np.float32(test_data)/255.\n",
        "        test_labels=f[('labels')][:]\n",
        "    return (train_data, train_labels), (val_data, val_labels), (test_data, test_labels)\n",
        "\n",
        "#shows 20 images from a set\n",
        "def showEm(examples,nrows = 4,ncols = 5):\n",
        "    plt.figure(figsize=(ncols*2, nrows*2))\n",
        "\n",
        "    for i in range(20):\n",
        "        plt.subplot(nrows, ncols, i+1)\n",
        "        plt.imshow(examples[i].reshape((28,28)), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "#preps data to go into CLIP\n",
        "def convertToPIL(img_set):\n",
        "  notLabels = img_set[0]\n",
        "  imList = []\n",
        "  for i in range(len(notLabels)):\n",
        "    imList.append(Image.fromarray(notLabels[i]))\n",
        "  return imList\n",
        "\n",
        "#gets embeds\n",
        "def getEmbeddings(conv_img_set):\n",
        "  image_features = []\n",
        "  #print(len(conv_img_set))\n",
        "  for i in range(len(conv_img_set)):\n",
        "    with torch.no_grad():\n",
        "        prepped = preprocess(conv_img_set[i]).unsqueeze(0).to(device)\n",
        "        image_features.append(model.encode_image(prepped))\n",
        "    #if (i % 500 == 0):\n",
        "      #print(i)\n",
        "  return image_features\n",
        "\n",
        "#moves from tensor to np\n",
        "def switchToNP(data_):\n",
        "  converted = []\n",
        "  for i in range(len(data_)):\n",
        "    converted.append(data_[i].cpu().numpy())\n",
        "  return converted\n",
        "\n",
        "\n",
        "#driver function for process\n",
        "def driver_conv(data_):\n",
        "  data_conv = convertToPIL(data_)\n",
        "\n",
        "  return (np.concatenate(switchToNP(getEmbeddings(data_conv)), axis=0), data_[1])\n",
        "\n",
        "#minimax finder\n",
        "def trainByPct():\n",
        "\n",
        "  for blur_pct in [0,25,50]:\n",
        "    for shift_pct in [0,25,50]:\n",
        "      raw, blur, shift = trainSplit(blur_pct, shift_pct)\n",
        "      #print(raw[0].shape)\n",
        "      #print(raw[1].shape)\n",
        "      #print(blur[0].shape)\n",
        "      #print(blur[1].shape)\n",
        "      #print(shift[0].shape)\n",
        "      #print(shift[1].shape)\n",
        "\n",
        "      this_trainSet_dat = np.concatenate((raw[0],blur[0],shift[0]), axis=0)\n",
        "      this_trainSet_lab = np.concatenate((raw[1],blur[1],shift[1]), axis=0)\n",
        "\n",
        "      classifier = LinearSVC().fit(this_trainSet_dat,this_trainSet_lab)\n",
        "      #classifier = classifier.partial_fit(this_split_blur_embeds_w_labels[0],this_split_blur_embeds_w_labels[1])\n",
        "      #classifier = classifier.partial_fit(this_split_shift_embeds_w_labels[0],this_split_shift_embeds_w_labels[1])\n",
        "\n",
        "      print(\"Blur pct: \" + str(blur_pct) + \" Shift pct: \" + str(shift_pct) + \" Untransformed score: \" + str(classifier.score(test_conv[0],test_raw[1])) + \" Blur score: \" + str(classifier.score(test_blur_conv[0],test_raw[1]))+ \" Shift score \" + str(classifier.score(test_shift_conv[0],test_raw[1])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M24Hx-HPu04b"
      },
      "outputs": [],
      "source": [
        "#raw versions of data area actual image data, conv versions are transformed embeddings\n",
        "data_now = get_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#river_conv(train_raw)[0].shape"
      ],
      "metadata": {
        "id": "TqnV90pMFK0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def add_blur_to_subset(X_train, pct, kernel_size):\n",
        "    num_images = X_train.shape[0]\n",
        "    num_images_blurred = int(num_images * pct)\n",
        "    indices_blurred = np.random.choice(num_images, num_images_blurred, replace=False)\n",
        "    \n",
        "    X_train_blurred = X_train.copy()\n",
        "    for index in indices_blurred:\n",
        "        image = X_train_blurred[index]\n",
        "        blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
        "        X_train_blurred[index] = blurred_image\n",
        "    \n",
        "    return X_train_blurred\n",
        "\n",
        "def shift_image(image, max_shift):\n",
        "    shift_x = np.random.randint(-max_shift, max_shift + 1)\n",
        "    shift_y = np.random.randint(-max_shift, max_shift + 1)\n",
        "    rows, cols = image.shape\n",
        "    M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
        "    shifted_image = cv2.warpAffine(image, M, (cols, rows))\n",
        "    return shifted_image\n",
        "\n",
        "def apply_shift_to_subset(X_train, pct, max_shift):\n",
        "    num_images = X_train.shape[0]\n",
        "    num_images_shifted = int(num_images * pct)\n",
        "    indices_shifted = np.random.choice(num_images, num_images_shifted, replace=False)\n",
        "\n",
        "    X_train_shifted = X_train.copy()\n",
        "    for index in indices_shifted:\n",
        "        image = X_train_shifted[index]\n",
        "        shifted_image = shift_image(image, max_shift)\n",
        "        X_train_shifted[index] = shifted_image\n",
        "\n",
        "    return X_train_shifted"
      ],
      "metadata": {
        "id": "bzQdedlN8cQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_blurred = add_blur_to_subset(data_now[0], 1.0, 9)\n",
        "images_shifted = apply_shift_to_subset(data_now[0], 1.0, 7)"
      ],
      "metadata": {
        "id": "JkKjRAq18bsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = (data_now[0][0:60000], data_now[1][0:60000])\n",
        "test_raw = (data_now[0][60000:70000], data_now[1][60000:70000])\n",
        "\n",
        "train_blur = (images_blurred[0:60000], data_now[1][0:60000])\n",
        "test_blur = (images_blurred[60000:70000], data_now[1][60000:70000])\n",
        "\n",
        "\n",
        "train_shift = (images_shifted[0:60000], data_now[1][0:60000])\n",
        "test_shift = (images_shifted[60000:70000], data_now[1][60000:70000])"
      ],
      "metadata": {
        "id": "gZoaec3y6RpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeatRun = True\n",
        "this_split_raw_embeds_w_labels = 0\n",
        "this_split_blur_embeds_w_labels = 0\n",
        "this_split_shift_embeds_w_labels = 0\n",
        "test_conv = 0\n",
        "test_blur_conv = 0\n",
        "test_shift_conv = 0"
      ],
      "metadata": {
        "id": "nmXM4WAbCoOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(repeatRun is False):\n",
        "  this_split_raw_embeds_w_labels = driver_conv(train_raw)\n",
        "  np.save('data1.npy', this_split_raw_embeds_w_labels[0])\n",
        "  this_split_blur_embeds_w_labels = driver_conv(train_blur)#apply blur\n",
        "  np.save('data2.npy', this_split_blur_embeds_w_labels[0])\n",
        "  this_split_shift_embeds_w_labels = driver_conv(train_shift)#apply shift\n",
        "  np.save('data3.npy', this_split_shift_embeds_w_labels[0])\n",
        "  test_conv = driver_conv(test_raw)\n",
        "  np.save('test.npy', test_conv[0])\n",
        "  test_blur_conv = driver_conv(test_blur)\n",
        "  np.save('testB.npy', test_blur_conv[0])\n",
        "  test_shift_conv = driver_conv(test_shift)\n",
        "  np.save('testS.npy', test_shift_conv[0])\n",
        "else:\n",
        "  this_split_raw_embeds_w_labels = (np.load('data1.npy'),data_now[1][0:60000])\n",
        "  this_split_blur_embeds_w_labels = (np.load('data2.npy'),data_now[1][0:60000])\n",
        "  this_split_shift_embeds_w_labels = (np.load('data3.npy'),data_now[1][0:60000])\n",
        "  test_conv = (np.load('test.npy'), data_now[1][60000:70000])\n",
        "  test_blur_conv = (np.load('testB.npy'), data_now[1][60000:70000])\n",
        "  test_shift_conv = (np.load('testS.npy'), data_now[1][60000:70000])"
      ],
      "metadata": {
        "id": "-a25IaXRvY-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainByPct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoZl2fpE_qXy",
        "outputId": "fb045859-bfeb-4062-93ed-94b53bb02497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 0 Shift pct: 0 Untransformed score: 0.8233 Blur score: 0.1064 Shift score 0.4175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 0 Shift pct: 25 Untransformed score: 0.8051 Blur score: 0.1064 Shift score 0.6162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 0 Shift pct: 50 Untransformed score: 0.7867 Blur score: 0.1064 Shift score 0.6544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 25 Shift pct: 0 Untransformed score: 0.8169 Blur score: 0.1064 Shift score 0.4116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 25 Shift pct: 25 Untransformed score: 0.794 Blur score: 0.1064 Shift score 0.6204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 25 Shift pct: 50 Untransformed score: 0.7608 Blur score: 0.1064 Shift score 0.6625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 50 Shift pct: 0 Untransformed score: 0.8047 Blur score: 0.0961 Shift score 0.4067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 50 Shift pct: 25 Untransformed score: 0.7666 Blur score: 0.0991 Shift score 0.6324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blur pct: 50 Shift pct: 50 Untransformed score: 0.6927 Blur score: 0.1064 Shift score 0.6648\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}